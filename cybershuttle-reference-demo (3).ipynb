{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bc2160d",
   "metadata": {},
   "source": [
    "# üëã Cybershuttle Demo Notebook\n",
    "\n",
    "Welcome to the Cybershuttle demo notebook! This notebook walks you through the basic steps of running a scientific or AI computation using Cybershuttle, starting locally and scaling to remote clusters.\n",
    "\n",
    "---\n",
    "\n",
    "**Goals of this notebook:**\n",
    "- Submit a simple Python script that squares a number\n",
    "- Run it both locally and remotely\n",
    "- Learn to track and retrieve results via Cybershuttle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3761e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyopenssl 23.2.0 requires cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0, but you have cryptography 44.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Loaded airavata_jupyter_magic (2.0.12) \n",
      "(current runtime = local)\n",
      "\n",
      "  %authenticate                      -- Authenticate to access high-performance runtimes.\n",
      "  %request_runtime <rt> [args]       -- Request a runtime named <rt> with configuration <args>. Call multiple times to request multiple runtimes.\n",
      "  %restart_runtime <rt>              -- Restart runtime <rt>. Run this if you install new dependencies or if the runtime hangs.\n",
      "  %stop_runtime <rt>                 -- Stop runtime <rt> when no longer needed.\n",
      "  %switch_runtime <rt>               -- Switch active runtime to <rt>. All subsequent executions will use this runtime.\n",
      "  %%run_on <rt>                      -- Force a cell to always execute on <rt>, regardless of the active runtime.\n",
      "  %stat_runtime <rt>                 -- Show the status of runtime <rt>.\n",
      "  %copy_data <r1:file1> <r2:file2>   -- Copy <file1> in <r1> to <file2> in <r2>.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# üõ†Ô∏è Install and Import Apache Airavata, the software which powers Cybershuttle\n",
    "%pip install -q --no-cache-dir --force-reinstall airavata-python-sdk[notebook]\n",
    "import airavata_jupyter_magic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4b1326",
   "metadata": {},
   "source": [
    "## üíª Step 1: Run simple scripts locally on the Cybershuttle hub. The same example can be replicated locally. \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e126455d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Metadata =====\n",
      "Hostname   : 64e7c208d4e6\n",
      "Timestamp  : 2025-04-24 22:10:37\n",
      "========================\n",
      "\n",
      "10! = 3628800\n"
     ]
    }
   ],
   "source": [
    "# factorial example\n",
    "import socket\n",
    "import time\n",
    "import math\n",
    "\n",
    "# Input value\n",
    "n = 10  # You can change this to any integer\n",
    "\n",
    "# Compute factorial\n",
    "result = math.factorial(n)\n",
    "\n",
    "# Metadata\n",
    "hostname = socket.gethostname()\n",
    "timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Output\n",
    "print(\"===== Job Metadata =====\")\n",
    "print(f\"Hostname   : {hostname}\")\n",
    "print(f\"Timestamp  : {timestamp}\")\n",
    "print(\"========================\\n\")\n",
    "print(f\"{n}! = {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ae0f4",
   "metadata": {},
   "source": [
    "## üöÄ Step 3: Authenticate with Cybershuttle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "642e60ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Authenticated.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Authenticated.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting runtime=hpc_cpu\n",
      "cpuCount: 4\n",
      "experimentName: CS_Agent\n",
      "group: Default\n",
      "libraries:\n",
      "- python=3.10\n",
      "- pip\n",
      "memory: 0\n",
      "mounts:\n",
      "- cybershuttle-reference:/cybershuttle_data/cybershuttle-reference\n",
      "nodeCount: 1\n",
      "pip: []\n",
      "queue: cloud\n",
      "remoteCluster: NeuroData25VC1\n",
      "wallTime: 60\n",
      "\n",
      "Requested runtime=hpc_cpu. state=EXECUTING\n",
      "Switched to runtime=hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "%authenticate\n",
    "%request_runtime hpc_cpu --file=cybershuttle.yml --walltime=60 --use=NeuroData25VC1:cloud,expanse:shared,anvil:shared\n",
    "%switch_runtime hpc_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4294c28b-53ec-40d1-8764-be5a7fd54b4f",
   "metadata": {},
   "source": [
    "## 3.1: install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d753bfee-92e1-48d7-8a7c-b3ba0aff3d81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[32m‚†∏\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
      "\u001b[1A\u001b[2K\u001b[2J\u001b[HSuccessfully installed accelerate-1.6.0 altair-5.5.0 attrs-25.3.0 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.18.0 fsspec-2025.3.2 gitdb-4.0.12 gitpython-3.1.44 huggingface-hub-0.30.2 idna-3.10 joblib-1.4.2 jsonschema-4.23.0 jsonschema-specifications-2025.4.1 mpmath-1.3.0 narwhals-1.36.0 networkx-3.4.2 numpy-2.2.5 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 packaging-24.2 pandas-2.2.3 pillow-11.2.1 protobuf-5.29.4 pyarrow-19.0.1 pydeck-0.9.1 pytz-2025.2 pyyaml-6.0.2 referencing-0.36.2 regex-2024.11.6 requests-2.32.3 rpds-py-0.24.0 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.2 sentencepiece-0.2.0 smmap-5.0.2 streamlit-1.44.1 sympy-1.13.3 tenacity-9.1.2 threadpoolctl-3.6.0 tokenizers-0.21.1 toml-0.10.2 torch-2.7.0 tqdm-4.67.1 transformers-4.51.3 triton-3.3.0 tzdata-2025.2 urllib3-2.4.0 vaderSentiment-3.3.2 watchdog-6.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: streamlit in /scratch/envs/94be70b6/lib/python3.10/site-packages (1.44.1)\n",
      "Requirement already satisfied: transformers in /scratch/envs/94be70b6/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: torch in /scratch/envs/94be70b6/lib/python3.10/site-packages (2.7.0)\n",
      "Requirement already satisfied: sentencepiece in /scratch/envs/94be70b6/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: scikit-learn in /scratch/envs/94be70b6/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: accelerate in /scratch/envs/94be70b6/lib/python3.10/site-packages (1.6.0)\n",
      "Requirement already satisfied: vaderSentiment in /scratch/envs/94be70b6/lib/python3.10/site-packages (3.3.2)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from streamlit) (2.2.5)\n",
      "Requirement already satisfied: packaging<25,>=20 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from streamlit) (11.2.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from streamlit) (5.29.4)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from streamlit) (19.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from streamlit) (4.13.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: filelock in /scratch/envs/94be70b6/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from triton==3.3.0->torch) (79.0.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: psutil in /scratch/envs/94be70b6/lib/python3.10/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (1.36.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
      "Requirement already satisfied: six>=1.5 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit transformers torch sentencepiece scikit-learn accelerate vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8f309ed-231e-4031-b9fe-4092fedb720d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[32m‚†π\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
      "\u001b[1A\u001b[2K\u001b[2J\u001b[HCollecting hf_xet\n",
      "  Using cached hf_xet-1.0.4-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\n",
      "Collecting pyngrok\n",
      "  Using cached pyngrok-7.2.5-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from pyngrok) (6.0.2)\n",
      "Using cached hf_xet-1.0.4-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (54.0 MB)\n",
      "Using cached pyngrok-7.2.5-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: pyngrok, hf_xet\n",
      "Successfully installed hf_xet-1.0.4 pyngrok-7.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hf_xet pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80269933-5f76-40f2-b489-9f46d886eaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[32m‚†π\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
      "\u001b[1A\u001b[2K\u001b[2J\u001b[HCollecting ipywidgets\n",
      "  Using cached ipywidgets-8.1.6-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from ipywidgets) (8.35.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Using cached widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.14 (from ipywidgets)\n",
      "  Using cached jupyterlab_widgets-3.0.14-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in /scratch/envs/94be70b6/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in /scratch/envs/94be70b6/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /scratch/envs/94be70b6/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /scratch/envs/94be70b6/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.13.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /scratch/envs/94be70b6/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /scratch/envs/94be70b6/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /scratch/envs/94be70b6/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Using cached ipywidgets-8.1.6-py3-none-any.whl (139 kB)\n",
      "Using cached jupyterlab_widgets-3.0.14-py3-none-any.whl (213 kB)\n",
      "Using cached widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.6 jupyterlab_widgets-3.0.14 widgetsnbextension-4.0.14\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82096e8d",
   "metadata": {},
   "source": [
    "## üì° Step 4: Just write code and run as if you would run locally, cybershuttle will move the required data, code and execute remotely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54ca0e90-3721-4416-ab69-ad0082529fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[32m‚†π\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
      "\u001b[1A\u001b[2K\u001b[2J\u001b[Htesting\n"
     ]
    }
   ],
   "source": [
    "c = \"\"\"from transformers import pipeline\n",
    "import numpy as np\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize both models\n",
    "hf_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"finiteautomata/bertweet-base-sentiment-analysis\",\n",
    "    top_k=None\n",
    ")\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "def classify_sentiment(input_text):\n",
    "    \n",
    "    #Hybrid sentiment analysis combining transformer models with VADER intensity analysis\n",
    "    #Returns formatted string with nuanced sentiment assessment\n",
    "    \n",
    "    try:\n",
    "        # Get HuggingFace predictions\n",
    "        hf_results = hf_classifier(input_text, truncation=True)[0]\n",
    "        pos_score = next(r['score'] for r in hf_results if r['label'] == 'POS')\n",
    "        neg_score = next(r['score'] for r in hf_results if r['label'] == 'NEG')\n",
    "        \n",
    "        # Get VADER intensity scores\n",
    "        vader_scores = vader.polarity_scores(input_text)\n",
    "        \n",
    "        # Combined weighted score (70% HF, 30% VADER)\n",
    "        combined_pos = (pos_score * 0.7) + (vader_scores['pos'] * 0.3)\n",
    "        combined_neg = (neg_score * 0.7) + (vader_scores['neg'] * 0.3)\n",
    "        \n",
    "        # Determine final sentiment\n",
    "        if combined_pos > combined_neg:\n",
    "            sentiment = \"POSITIVE\"\n",
    "            base_confidence = combined_pos\n",
    "            intensity = vader_scores['pos']\n",
    "        else:\n",
    "            sentiment = \"NEGATIVE\"\n",
    "            base_confidence = combined_neg\n",
    "            intensity = vader_scores['neg']\n",
    "        \n",
    "        # Dynamic confidence adjustment based on intensity\n",
    "        adjusted_confidence = min(base_confidence * (1 + intensity), 0.99)\n",
    "        \n",
    "        # Strength classification with wider bands\n",
    "        strength_ranges = [\n",
    "            (0.9, \"Extremely\"),\n",
    "            (0.8, \"Very\"),\n",
    "            (0.7, \"Strongly\"),\n",
    "            (0.6, \"Fairly\"),\n",
    "            (0.5, \"Moderately\"),\n",
    "            (0.4, \"Somewhat\"),\n",
    "            (0, \"Slightly\")\n",
    "        ]\n",
    "        \n",
    "        strength = next(\n",
    "            desc for threshold, desc in strength_ranges \n",
    "            if adjusted_confidence >= threshold\n",
    "        )\n",
    "        \n",
    "        # Add intensity qualifiers\n",
    "        modifiers = {\n",
    "            \"Extremely\": \"!\",\n",
    "            \"Very\": \"!\",\n",
    "            \"Strongly\": \"\",\n",
    "            \"Fairly\": \"\",\n",
    "            \"Moderately\": \" (somewhat)\",\n",
    "            \"Somewhat\": \" (mildly)\",\n",
    "            \"Slightly\": \" (barely)\"\n",
    "        }\n",
    "        \n",
    "        return (\n",
    "            f\"{strength} {sentiment}{modifiers[strength]} \"\n",
    "            f\"(Confidence: {adjusted_confidence:.0%})\"\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Analysis error: {str(e)}\"\n",
    "\"\"\"\n",
    "with open(\"classify.py\", \"w\") as f:\n",
    "    f.write(c)\n",
    "\n",
    "f.close()\n",
    "print(\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f777fcf4-c294-4524-9a73-b2bedd6c1886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[32m‚†∏\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
      "\u001b[1A\u001b[2K\u001b[2J\u001b[Htesting\n"
     ]
    }
   ],
   "source": [
    "t = \"\"\"from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Function to get the model name based on the source and target language\n",
    "def get_model_name(source_language, target_language):\n",
    "    return f\"Helsinki-NLP/opus-mt-{source_language}-{target_language}\"\n",
    "\n",
    "# Function to perform translation\n",
    "def translate_text(input_text, source_language='en', target_language='es'):\n",
    "    model_name = get_model_name(source_language, target_language)\n",
    "    \n",
    "    # Load the MarianMT model and tokenizer for the specific language pair\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Prepare the input text with the correct prefix for translation\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    # Generate the translation\n",
    "    translated_ids = model.generate(input_ids, max_length=150, num_beams=4, early_stopping=True)\n",
    "    \n",
    "    # Decode the translated output\n",
    "    translation = tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return translation\n",
    "\"\"\"\n",
    "with open(\"translate.py\", \"w\") as f:\n",
    "    f.write(code)\n",
    "\n",
    "f.close()\n",
    "print(\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82710dda-5cb2-4e1e-aba4-63cdfc385361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[32m‚†∏\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
      "\u001b[1A\u001b[2K\u001b[2J\u001b[Htesting\n"
     ]
    }
   ],
   "source": [
    "q = \"\"\"from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "model_name = \"t5-base\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "def answer_question(context, question):\n",
    "    \n",
    "    #Enhanced question answering with T5\n",
    "    #Args:\n",
    "    #    context: Background information text (1-3 sentences work best)\n",
    "    #    question: Clear question about the context\n",
    "    #Returns:\n",
    "    #    Concise answer extracted from context\n",
    "    \n",
    "    # Improved input formatting\n",
    "    input_text = f\"answer question based on context: {question} context: {context}\"\n",
    "    \n",
    "    # Better tokenization with attention to question-context balance\n",
    "    input_ids = tokenizer.encode(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"  # Helps with consistency\n",
    "    )\n",
    "    \n",
    "    # Optimized generation parameters\n",
    "    answer_ids = model.generate(\n",
    "        input_ids,\n",
    "        max_length=100,        # More concise answers\n",
    "        min_length=5,          # Avoid empty answers\n",
    "        num_beams=5,           # Better quality than 4 beams\n",
    "        early_stopping=True,\n",
    "        repetition_penalty=2.5, # Reduce repeated phrases\n",
    "        length_penalty=1.5,     # Prefer shorter answers\n",
    "        no_repeat_ngram_size=3, # Prevent word repetition\n",
    "        temperature=0.7         # Adds slight creativity\n",
    "    )\n",
    "    \n",
    "    # Improved decoding\n",
    "    answer = tokenizer.decode(\n",
    "        answer_ids[0],\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=True\n",
    "    )\n",
    "    \n",
    "    # Post-processing for better results\n",
    "    answer = answer.split(\".\")[0]  # Take the first complete thought\n",
    "    answer = answer.strip()\n",
    "    \n",
    "    return answer if answer else \"I couldn't find an answer in the context.\"\n",
    "    \"\"\"\n",
    "with open(\"qa.py\", \"w\") as f:\n",
    "    f.write(code)\n",
    "\n",
    "f.close()\n",
    "print(\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5be452b7-0634-49a3-bd8e-8a1ee88be2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[32m‚†∏\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
      "\u001b[1A\u001b[2K\u001b[2J\u001b[Htesting\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\"from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "model_name = \"t5-base\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "def summarize_text(input_text):\n",
    "    # Preprocess input\n",
    "    input_text = input_text.strip()\n",
    "    if len(input_text.split()) < 15:  # Minimum words needed for good summary\n",
    "        return \"Input too short - please provide at least 15-20 words for meaningful summarization.\"\n",
    "    \n",
    "    # Format for T5 (crucial!)\n",
    "    input_text = \"summarize: \" + input_text\n",
    "    \n",
    "    # Tokenize with better truncation\n",
    "    input_ids = tokenizer.encode(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"  # Helps with short texts\n",
    "    )\n",
    "    \n",
    "    # Generate with adjusted parameters\n",
    "    summary_ids = model.generate(\n",
    "        input_ids,\n",
    "        max_length=100,       # Reduced from 150\n",
    "        min_length=30,        # Reduced from 50\n",
    "        length_penalty=3.0,   # Increased to favor shorter summaries\n",
    "        num_beams=6,          # Increased from 4\n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=3  # Prevents word repetition\n",
    "    )\n",
    "    \n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Post-process output\n",
    "    if summary.lower() == input_text[11:].lower():  # If output == input\n",
    "        return \"Summary failed (input may be too short or unclear). Try with longer text.\"\n",
    "    \n",
    "    return summary\n",
    "\"\"\"\n",
    "with open(\"summarize.py\", \"w\") as f:\n",
    "    f.write(code)\n",
    "\n",
    "f.close()\n",
    "print(\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81f44b74-b9ec-4f13-87a0-c04353e4af03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[32m‚†∏\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
      "\u001b[1A\u001b[2K\u001b[2J\u001b[Htesting\n"
     ]
    }
   ],
   "source": [
    "code = \"\"\"import streamlit as st\n",
    "from summarize import summarize_text\n",
    "from translate import translate_text\n",
    "from qa import answer_question\n",
    "from classify import classify_sentiment\n",
    "# Language mapping dictionary\n",
    "LANGUAGE_MAP = {\n",
    "    \"en\": \"English\",\n",
    "    \"es\": \"Espa√±ol (Spanish)\",\n",
    "    \"fr\": \"Fran√ßais (French)\",\n",
    "    \"de\": \"Deutsch (German)\",\n",
    "    \"it\": \"Italiano (Italian)\",\n",
    "    \"pt\": \"Portugu√™s (Portuguese)\",\n",
    "    \"ja\": \"Êó•Êú¨Ë™û (Japanese)\",\n",
    "    \"zh\": \"‰∏≠Êñá (Chinese)\"\n",
    "}\n",
    "\n",
    "def validate_input(task, input_text):\n",
    "    if not input_text.strip():\n",
    "        raise ValueError(\"Input text cannot be empty!\")\n",
    "    \n",
    "    if task == \"Answer Question\":\n",
    "        lines = input_text.strip().split(\"\\n\")\n",
    "        if len(lines) < 2:\n",
    "            raise ValueError(\n",
    "                \"For 'Answer Question', input must have:\\n\"\n",
    "                \"Line 1: Context (text with the answer)\\n\"\n",
    "                \"Line 2: Question\"\n",
    "            )\n",
    "    return True\n",
    "\n",
    "# --- Streamlit UI ---\n",
    "st.set_page_config(page_title=\"AI NLP Tool\", layout=\"centered\")\n",
    "st.title(\"üß† AI NLP Tool\")\n",
    "\n",
    "# Task selection\n",
    "task = st.selectbox(\"Select Task:\", [\"Summarize\", \"Translate\", \"Answer Question\", \"Classify\"])\n",
    "\n",
    "# Dynamic help text\n",
    "if task == \"Answer Question\":\n",
    "    st.info(\"‚ÑπÔ∏è For 'Answer Question', enter context (line 1) and question (line 2).\")\n",
    "elif task == \"Translate\":\n",
    "    st.info(\"‚ÑπÔ∏è Enter text and select languages from the dropdown menus.\")\n",
    "else:\n",
    "    st.info(\"‚ÑπÔ∏è Enter text and click 'Run Task'.\")\n",
    "\n",
    "# Text input\n",
    "input_text = st.text_area(\"Enter Input Text:\", height=200)\n",
    "\n",
    "# Translation language selectors\n",
    "if task == \"Translate\":\n",
    "    language_options = [f\"{code} - {name}\" for code, name in LANGUAGE_MAP.items()]\n",
    "    source_lang = st.selectbox(\"From:\", language_options, index=0)\n",
    "    target_lang = st.selectbox(\"To:\", language_options, index=1)\n",
    "\n",
    "# Run task\n",
    "if st.button(\"Run Task\"):\n",
    "    try:\n",
    "        # Validate input\n",
    "        validate_input(task, input_text)\n",
    "\n",
    "        if task == \"Summarize\":\n",
    "            result = summarize_text(input_text)\n",
    "        elif task == \"Translate\":\n",
    "            source_code = source_lang.split(\" - \")[0]\n",
    "            target_code = target_lang.split(\" - \")[0]\n",
    "            result = translate_text(input_text, source_code, target_code)\n",
    "        elif task == \"Answer Question\":\n",
    "            lines = input_text.strip().split(\"\\n\")\n",
    "            context, question = lines[0], lines[1]\n",
    "            result = answer_question(context, question)\n",
    "        elif task == \"Classify\":\n",
    "            result = classify_sentiment(input_text)\n",
    "        else:\n",
    "            result = \"Unknown task.\"\n",
    "\n",
    "        st.success(\"‚úÖ Task Completed\")\n",
    "        st.text_area(\"Result:\", value=result, height=200)\n",
    "\n",
    "    except Exception as e:\n",
    "        error_messages = {\n",
    "            \"ValueError\": str(e),\n",
    "            \"RuntimeError\": \"Model failed to process. Try shorter text.\",\n",
    "            \"IndexError\": \"For 'Answer Question', provide both context and question.\",\n",
    "        }\n",
    "        error_msg = error_messages.get(type(e).__name__, f\"An error occurred: {str(e)}\")\n",
    "        st.error(error_msg)\n",
    "\"\"\"\n",
    "with open(\"app.py\", \"w\") as f:\n",
    "    f.write(code)\n",
    "\n",
    "f.close()\n",
    "print(\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01f15209-7594-4438-acfc-d159a6d9a6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[32m‚†∏\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
      "\u001b[1A\u001b[2K\u001b[2J\u001b[HStreamlit app is running on port 8510.\n",
      "===== Job Metadata =====\n",
      "Hostname   : nsworkshopcpuvc1-compute-1.novalocal\n",
      "Timestamp  : 2025-04-24 22:45:44\n",
      "========================\n",
      "<IPython.lib.display.IFrame at 0x7f48c59065f0>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"600\"\n",
       "            src=\"https://localhost:8510\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import socket\n",
    "import os\n",
    "import time\n",
    "\n",
    "from IPython.display import IFrame\n",
    "# Function to chefrom IPython.display import IFrameck if a port is available\n",
    "def find_available_port(start_port=8501, max_tries=100):\n",
    "    for port in range(start_port, start_port + max_tries):\n",
    "        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        result = s.connect_ex(('localhost', port))\n",
    "        if result != 0:  # If the result is non-zero, the port is available\n",
    "            s.close()\n",
    "            return port\n",
    "        s.close()\n",
    "    raise Exception(\"No available ports found!\")\n",
    "\n",
    "# Find an available port\n",
    "port = find_available_port()\n",
    "\n",
    "# Create the command to run Streamlit on the available port\n",
    "streamlit_command = f\"streamlit run app.py --server.port {port} --server.headless true --server.enableCORS false > streamlit.log 2>&1 &\"\n",
    "\n",
    "# Run the Streamlit app in the background\n",
    "os.system(streamlit_command)\n",
    "#os.system(c2)\n",
    "\n",
    "print(f\"Streamlit app is running on port {port}.\")\n",
    "\n",
    "\n",
    "hostname = socket.gethostname()\n",
    "timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(\"===== Job Metadata =====\")\n",
    "print(f\"Hostname   : {hostname}\")\n",
    "print(f\"Timestamp  : {timestamp}\")\n",
    "print(\"========================\\n\")\n",
    "IFrame(src=f\"https://localhost:{port}\", width=900, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e787ba63",
   "metadata": {},
   "source": [
    "## ‚úÖ That's it!\n",
    "\n",
    "You‚Äôve now used Cybershuttle to run the same computation locally and remotely. You can use this pattern for scaling your research workflows!\n",
    "\n",
    "---\n",
    "\n",
    "### üîó Resources:\n",
    "- [Cybershuttle](https://cybershuttle.org)\n",
    "- [Cybershuttle GitHub](https://github.com/cyber-shuttle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b2b0704-3b42-4b57-8ca5-dec8863476c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[32m‚†∏\u001b[0m Connecting to=hpc_cpu... status=CONNECTED\n",
      "\u001b[1A\u001b[2K\u001b[2J\u001b[HCollecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\n",
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8509\n",
      "  Network URL: http://10.0.6.217:8509\n",
      "  External URL: http://149.165.159.166:8509\n"
     ]
    }
   ],
   "source": [
    "!tail -n 10 streamlit.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186fe3d4-d917-4d0e-912e-f38dc8dfe082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
